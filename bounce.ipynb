{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "import math\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=2., font=\"serif\", style=\"whitegrid\")\n",
    "import pandas as pd\n",
    "\n",
    "from mie2c.e2c import E2C, compute_loss, PWATransition\n",
    "from mie2c.bounce_model import (get_bounce_encoder, get_bounce_decoder,\n",
    "    get_bounce_transition, get_bounce_linear_transition, get_bounce_pwa_transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img(X, pos_bounds, radius=0.5, W=32):\n",
    "    x, y, vx, vy = X\n",
    "\n",
    "    # Check if center of ball outside image frame\n",
    "    if x < pos_bounds[0] or x > pos_bounds[1]:\n",
    "        return None\n",
    "    elif y < pos_bounds[0] or y > pos_bounds[1]:\n",
    "        return None\n",
    "\n",
    "    x_px = int(round(W * x / posbounds[1]))\n",
    "    y_px = int(round(W * y / posbounds[1]))\n",
    "    r_px = int(round(radius / pos_bounds[1] * W))\n",
    "\n",
    "    # Check if perimeter of ball outside image frame\n",
    "    if x_px+r_px > W or x_px-r_px < 0:\n",
    "        return None\n",
    "    elif y_px+r_px > W or y_px-r_px < 0:\n",
    "        return None\n",
    "\n",
    "    img = np.ones((3,W,W))\n",
    "    yy,xx = np.mgrid[:W, :W]\n",
    "    circle = (xx-x_px)**2 + (yy-y_px)**2\n",
    "    img[:, circle < r_px**2] = 0.\n",
    "\n",
    "    th = np.arctan2(vy,vx)\n",
    "    for rr in range(r_px):\n",
    "        img[0,int(y_px+rr*np.sin(th)), int(x_px+rr*np.cos(th))] = 1.\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x0, Ak, posbounds, rd, add_noise=False):\n",
    "    # x0: 4D vector (x,y,xd,yd)\n",
    "    # Ak: 4x4 transition matrix\n",
    "    # posbounds: [min,max] for x and y\n",
    "    update = Ak @ x0\n",
    "\n",
    "    if add_noise:\n",
    "        mn = np.array([0.1, 0.1])\n",
    "        cov = np.diag([0.05, 0.05])\n",
    "        frzn = stats.multivariate_normal(mn, cov)\n",
    "        update += frzn.rvs(1)\n",
    "\n",
    "    # Bounce the ball if needed\n",
    "    if update[0]-rd <= posbounds[0]:\n",
    "        update[0] = posbounds[0]+rd\n",
    "        update[2] *= -1.\n",
    "    elif update[0]+rd >= posbounds[1]:\n",
    "        update[0] = posbounds[1]-rd\n",
    "        update[2] *= -1.\n",
    "\n",
    "    if update[1]-rd <= posbounds[0]:\n",
    "        update[1] = posbounds[0]+rd\n",
    "        update[3] *= -1.\n",
    "    elif update[1]+rd >= posbounds[1]:\n",
    "        update[1] = posbounds[1]-rd\n",
    "        update[3] *= -1.\n",
    "\n",
    "    return update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4 \n",
    "dh = 0.05\n",
    "\n",
    "rd = 0.5\n",
    "posbounds = np.array([0,4]) # 4x4m square\n",
    "velmax = 10.\n",
    "\n",
    "Ak = np.eye(n)\n",
    "Ak[0:int(n/2), int(n/2):] = dh * np.eye(int(n/2))\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "W = 128\n",
    "\n",
    "# Training data\n",
    "NUM_DATA = 500\n",
    "NUM_STEPS = 10\n",
    "\n",
    "X = np.zeros((NUM_DATA,3,W,W))\n",
    "X_next = np.zeros((NUM_DATA,3,W,W))\n",
    "\n",
    "count, update_count = 0, 0\n",
    "while count < NUM_DATA:\n",
    "    if update_count % NUM_STEPS == 0:\n",
    "        # Restart episode\n",
    "        x0 = np.hstack((posbounds[1] * np.random.rand(2), velmax*np.ones(2)))\n",
    "        update_count = 0\n",
    "\n",
    "    img = create_img(x0, posbounds, radius=rd, W=W)\n",
    "    if img is None:\n",
    "        update_count = 0\n",
    "        continue\n",
    "\n",
    "    x0_new = step(x0, Ak, posbounds, rd)\n",
    "    img_new = create_img(x0_new, posbounds, radius=rd, W=W)\n",
    "    if img_new is None:\n",
    "        update_count = 0\n",
    "        continue\n",
    "\n",
    "    X[count,:,:,:] = img\n",
    "    X_next[count,:,:,:] = img_new\n",
    "\n",
    "    x0 = np.copy(x0_new)\n",
    "    count += 1\n",
    "    update_count += 1\n",
    "    \n",
    "# Training data\n",
    "NUM_TEST = 100\n",
    "\n",
    "X_test = np.zeros((NUM_TEST,3,W,W))\n",
    "X_next_test = np.zeros((NUM_TEST,3,W,W))\n",
    "\n",
    "count, update_count = 0, 0\n",
    "while count < NUM_TEST:\n",
    "    if update_count % NUM_STEPS == 0:\n",
    "        # Restart episode\n",
    "        x0 = np.hstack((posbounds[1] * np.random.rand(2), velmax*np.ones(2)))\n",
    "        update_count = 0\n",
    "\n",
    "    img = create_img(x0, posbounds, radius=rd, W=W)\n",
    "    if img is None:\n",
    "        update_count = 0\n",
    "        continue\n",
    "\n",
    "    x0_new = step(x0, Ak, posbounds, rd)\n",
    "    img_new = create_img(x0_new, posbounds, radius=rd, W=W)\n",
    "    if img_new is None:\n",
    "        update_count = 0\n",
    "        continue\n",
    "\n",
    "    X_test[count,:,:,:] = img\n",
    "    X_next_test[count,:,:,:] = img_new\n",
    "\n",
    "    x0 = np.copy(x0_new)\n",
    "    count += 1\n",
    "    update_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f745069ce10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 22\n",
    "img, img_next = X[idx], X_next[idx]\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow(img.transpose(1,2,0))\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(img_next.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_in = X[0].shape\n",
    "dim_z = 6\n",
    "dim_u = 0\n",
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, X, X_next, model_name, verbose=True, cuda=False):\n",
    "    if not os.path.exists('pytorch'):\n",
    "        os.makedirs('pytorch')\n",
    "    fn_pt_model = 'pytorch/{}.pt'.format(model_name)\n",
    "    dim_u = model.trans.dim_u\n",
    "\n",
    "    # training parameters\n",
    "    TRAINING_ITERATIONS = int(5000)\n",
    "    BATCH_SIZE = int(64)\n",
    "    CHECKPOINT_AFTER = int(1250)\n",
    "    SAVEPOINT_AFTER = int(2500)\n",
    "\n",
    "    KL_LAMBDA = .25\n",
    "    TEMP_LAMBDA = 10.\n",
    "\n",
    "    if cuda:\n",
    "        dataset = torch.utils.data.TensorDataset(torch.tensor(X).float().to(\"cuda\"), \\\n",
    "                                                 torch.tensor(X_next).float().to(\"cuda\"))\n",
    "        model = model.to(\"cuda\")\n",
    "    else:\n",
    "        dataset = torch.utils.data.TensorDataset(torch.tensor(X).float(), \\\n",
    "                                                 torch.tensor(X_next).float())    \n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    itr = 0\n",
    "    for epoch in range(TRAINING_ITERATIONS):\n",
    "        iter_count = 0\n",
    "        for x, x_next in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            action = torch.empty(NUM_DATA, dim_u)\n",
    "\n",
    "            model(x, action, x_next)\n",
    "            elbo_loss, kl_loss = compute_loss(model.x_dec, model.x_next_dec, model.x_next_pred_dec,\n",
    "                                              x, x_next,\n",
    "                                              model.Qz, model.Qz_next, model.Qz_next_pred)\n",
    "            loss = elbo_loss + KL_LAMBDA * kl_loss\n",
    "            if isinstance(model.trans, PWATransition):\n",
    "                loss += TEMP_LAMBDA * model.trans.temperature.pow(2)[0]\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if itr % CHECKPOINT_AFTER == 0:\n",
    "                print('Avg. loss: {}'.format(loss.item()))\n",
    "\n",
    "            if itr % SAVEPOINT_AFTER == 0:\n",
    "                torch.save(model.state_dict(), fn_pt_model)\n",
    "\n",
    "            iter_count += 1\n",
    "            itr += 1\n",
    "\n",
    "    if cuda:\n",
    "        model = model.to(\"cpu\")          \n",
    "        torch.cuda.empty_cache()\n",
    "    del dataset\n",
    "\n",
    "    torch.save(model.state_dict(), fn_pt_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2C Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_bounce_encoder(dim_in, dim_z)\n",
    "e2c_transition = get_bounce_transition(dim_z, dim_u)\n",
    "decoder = get_bounce_decoder(dim_z, dim_in)\n",
    "\n",
    "fn_e2c = 'model_e2c'\n",
    "model_e2c = E2C(encoder, e2c_transition, decoder)\n",
    "\n",
    "# if os.path.exists('pytorch/{}.pt'.format(fn_e2c)):\n",
    "#     model_e2c.load_state_dict(torch.load('pytorch/{}.pt'.format(fn_e2c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. loss: 39267.39365601242\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-c9633dc1efa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_e2c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_e2c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-97d4b73a509b>\u001b[0m in \u001b[0;36mtrain_vae\u001b[0;34m(model, X, X_next, model_name, verbose, cuda)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mTEMP_LAMBDA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs_231n/cs231n-project/cs231n_project/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs_231n/cs231n-project/cs231n_project/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_vae(model_e2c, X, X_next, fn_e2c, verbose=True, cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_low_rank = False  # True if A = I + r*v^T\n",
    "\n",
    "encoder = get_ball_encoder(dim_in, dim_z)\n",
    "lin_transition = get_ball_linear_transition(dim_z, dim_u, low_rank=use_low_rank)\n",
    "decoder = get_ball_decoder(dim_z, dim_in) \n",
    "\n",
    "fn_lin = 'model_lin'\n",
    "model_lin = E2C(encoder, lin_transition, decoder)\n",
    "\n",
    "# if os.path.exists('pytorch/{}.pt'.format(fn_lin)):\n",
    "#     model_lin.load_state_dict(torch.load('pytorch/{}.pt'.format(fn_lin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vae(model_lin, X, X_next, fn_lin, verbose=True, cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PWA Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_low_rank = False  # True if A = I + r*v^T\n",
    "num_modes = 2\n",
    "\n",
    "encoder = get_ball_encoder(dim_in, dim_z)\n",
    "pwa_transition = get_ball_pwa_transition(num_modes, dim_z, dim_u, low_rank=use_low_rank)\n",
    "decoder = get_ball_decoder(dim_z, dim_in) \n",
    "\n",
    "fn_pwa = 'model_pwa'\n",
    "model_pwa = E2C(encoder, pwa_transition, decoder)\n",
    "\n",
    "# if os.path.exists('pytorch/{}.pt'.format(fn_pwa)):\n",
    "#     model_pwa.load_state_dict(torch.load('pytorch/{}.pt'.format(fn_pwa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vae(model_pwa, X, X_next, fn_pwa, verbose=True, cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred_e2c = model_e2c.predict(torch.tensor(X_test).float(), torch.empty(NUM_TEST,1).float())\n",
    "l2_err_e2c = (x_pred_e2c - torch.tensor(X_test)).pow(2).sum(axis=1).sum(axis=1).sum(axis=1).pow(0.5).detach().cpu().numpy()\n",
    "\n",
    "x_pred_lin = model_lin.predict(torch.tensor(X_test).float(), torch.empty(NUM_TEST,1).float())\n",
    "l2_err_lin = (x_pred_lin - torch.tensor(X_test)).pow(2).sum(axis=1).sum(axis=1).sum(axis=1).pow(0.5).detach().cpu().numpy()\n",
    "\n",
    "x_pred_pwa = model_pwa.predict(torch.tensor(X_test).float(), torch.empty(NUM_TEST,1).float())\n",
    "l2_err_pwa = (x_pred_pwa - torch.tensor(X_test)).pow(2).sum(axis=1).sum(axis=1).sum(axis=1).pow(0.5).detach().cpu().numpy()\n",
    "\n",
    "print(\"e2c: \" + str(l2_err_e2c.mean()))\n",
    "print(\"linear: \" + str(l2_err_lin.mean()))\n",
    "print(\"pwa: \" + str(l2_err_pwa.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'E2C':l2_err_e2c, 'Linear':l2_err_lin, 'PWA':l2_err_pwa}\n",
    "results = pd.DataFrame(results)\n",
    "\n",
    "ax1 = sns.boxplot(data=results, palette=\"Set3\")\n",
    "ax1.set(xlabel=\"\", ylabel=\"Reconstruction Loss\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylim(0, int(math.ceil(np.max(np.maximum(l2_err_lin, l2_err_e2c, l2_err_pwa)) / 10.0)) * 10)\n",
    "\n",
    "figure = ax1.get_figure()\n",
    "figure.savefig(\"loss.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n_project",
   "language": "python",
   "name": "cs231n_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
