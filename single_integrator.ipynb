{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "from src.configs import BallEncoder, BallDecoder, BallTransition\n",
    "from src.e2c import E2C, compute_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to create (3,32,32) tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img(X, pos_bounds, radius=0.5, W=32):\n",
    "    x, y, vx, vy = X\n",
    "\n",
    "    # Check if center of ball outside image frame\n",
    "    if x < pos_bounds[0] or x > pos_bounds[1]:\n",
    "        return None\n",
    "    elif y < pos_bounds[0] or y > pos_bounds[1]:\n",
    "        return None\n",
    "\n",
    "    x_px = int(round(W * x / posbounds[1]))\n",
    "    y_px = int(round(W * y / posbounds[1]))\n",
    "    r_px = int(round(radius / pos_bounds[1] * W))\n",
    "\n",
    "    # Check if perimeter of ball outside image frame\n",
    "    if x_px+r_px > W or x_px-r_px < 0:\n",
    "        return None\n",
    "    elif y_px+r_px > W or y_px-r_px < 0:\n",
    "        return None\n",
    "\n",
    "    img = np.ones((3,W,W))\n",
    "    yy,xx = np.mgrid[:W, :W]\n",
    "    circle = (xx-x_px)**2 + (yy-y_px)**2\n",
    "    img[:, circle < r_px**2] = 0.\n",
    "\n",
    "    th = np.arctan2(vy,vx)\n",
    "    for rr in range(r_px):\n",
    "        img[0,int(y_px+rr*np.sin(th)), int(x_px+rr*np.cos(th))] = 1.\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PWA single integrator kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x0, Ak, add_noise=False):\n",
    "    # If ball in left-half plane, flip sign of vx\n",
    "    if x0[0] < 0.5*posbounds[1]:\n",
    "        x0[2] *= -1.\n",
    "\n",
    "    update = Ak @ x0\n",
    "    if add_noise:\n",
    "        mn = np.array([0.1, 0.1])\n",
    "        cov = np.diag([0.05, 0.05])\n",
    "        frzn = stats.multivariate_normal(mn, cov)\n",
    "        update += frzn.rvs(1)\n",
    "    return update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4 \n",
    "dh = 0.1\n",
    "\n",
    "posbounds = np.array([0,4]) # 4x4m square\n",
    "velmax = 10.\n",
    "\n",
    "Ak = np.eye(n)\n",
    "Ak[0:int(n/2), int(n/2):] = dh * np.eye(int(n/2))\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "W = 32\n",
    "NUM_DATA = 500\n",
    "\n",
    "X = np.zeros((NUM_DATA,3,W,W))\n",
    "X_next = np.zeros((NUM_DATA,3,W,W))\n",
    "\n",
    "count = 0\n",
    "while count < NUM_DATA:\n",
    "    x0 = np.hstack((posbounds[1] * np.random.rand(2), velmax*np.ones(2)))\n",
    "\n",
    "    img = create_img(x0, posbounds)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    x0_new = step(x0, Ak)\n",
    "    img_new = create_img(x0_new, posbounds)\n",
    "    if img_new is None:\n",
    "        continue\n",
    "\n",
    "    X[count,:,:,:] = img\n",
    "    X_next[count,:,:,:] = img_new\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f959d0be0f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 1\n",
    "img, img_next = X[idx], X_next[idx]\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow(img.transpose(1,2,0))\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(img_next.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct encoder/decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_in = X[0].shape\n",
    "dim_z = 6\n",
    "dim_u = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "model = E2C(dim_in, dim_z, dim_u, config='ball')\n",
    "model.to(gpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = torch.from_numpy(X[:2]).float().to(gpu)\n",
    "# mean, logvar = model.encode(inp)\n",
    "# model.decode(mean).shape\n",
    "\n",
    "# before = torch.from_numpy(X[:2]).float().to(gpu)\n",
    "# after = torch.from_numpy(X_next[:2]).float().to(gpu)\n",
    "# ctrl = torch.empty(NUM_DATA, dim_u).to(gpu)\n",
    "\n",
    "# model.forward(before, ctrl, after);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reconstruction loss: 0.1284363567829132\n",
      "Average reconstruction loss: 0.1266273409128189\n",
      "Average reconstruction loss: 0.12596504390239716\n",
      "Average reconstruction loss: 0.11259845644235611\n",
      "Average reconstruction loss: 0.12412288039922714\n",
      "Average reconstruction loss: 0.1151428073644638\n",
      "Average reconstruction loss: 0.11327555775642395\n",
      "Average reconstruction loss: 0.11679643392562866\n",
      "Average reconstruction loss: 0.12270402908325195\n",
      "Average reconstruction loss: 0.122612863779068\n",
      "Average reconstruction loss: 0.12264701724052429\n",
      "Average reconstruction loss: 0.12260034680366516\n",
      "Average reconstruction loss: 0.11205693334341049\n",
      "Average reconstruction loss: 0.1226540207862854\n",
      "Average reconstruction loss: 0.11260849237442017\n",
      "Average reconstruction loss: 0.11186175793409348\n",
      "Average reconstruction loss: 0.11168314516544342\n",
      "Average reconstruction loss: 0.1226535439491272\n",
      "Average reconstruction loss: 0.11080261319875717\n",
      "Average reconstruction loss: 0.1123003140091896\n",
      "Average reconstruction loss: 0.11254478991031647\n",
      "Average reconstruction loss: 0.1226208508014679\n",
      "Average reconstruction loss: 0.11170026659965515\n",
      "Average reconstruction loss: 0.12260738015174866\n",
      "Average reconstruction loss: 0.12263477593660355\n",
      "Average reconstruction loss: 0.12257306277751923\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0bed88489a70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mbefore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mafter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_next\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# training parameters\n",
    "TRAINING_ITERATIONS = int(10000)\n",
    "BATCH_SIZE = int(32)\n",
    "CHECKPOINT_AFTER = int(1500)\n",
    "SAVEPOINT_AFTER = int(1000)\n",
    "TEST_BATCH_SIZE = int(128)\n",
    "\n",
    "rand_idx = list(np.arange(0, X_next.shape[0]-1))\n",
    "indices = [rand_idx[ii * BATCH_SIZE:(ii + 1) * BATCH_SIZE] \\\n",
    "    for ii in range((len(rand_idx) + BATCH_SIZE - 1)     // BATCH_SIZE)]\n",
    "if len(indices[-1]) == 1:\n",
    "    # make sure batch doesn't just have one data point\n",
    "    indices[-1].append(indices[-1][0])\n",
    "\n",
    "itr = 1\n",
    "for epoch in range(TRAINING_ITERATIONS):\n",
    "    for ii, idx in enumerate(indices):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        before = torch.from_numpy(X[idx]).float().to(gpu)\n",
    "        ctrl = torch.empty(len(idx), dim_u).to(gpu)\n",
    "        after = torch.from_numpy(X_next[idx]).float().to(gpu)\n",
    "#         after = np.copy(X[idx])\n",
    "#         for jj in range(len(idx)):\n",
    "#             after[jj,:,:,:] = X[0]\n",
    "#         after = torch.from_numpy(after).float().to(gpu)\n",
    "\n",
    "        next_pre_rec = model(before, ctrl, after)\n",
    "\n",
    "        loss_rec, loss_trans = compute_loss(\\\n",
    "            model.x_dec, model.x_next_pred_dec, \\\n",
    "            before, after, \\\n",
    "            model.Qz, model.Qz_next_pred, model.Qz_next)\n",
    "\n",
    "        loss = loss_rec # + loss_trans\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if itr % CHECKPOINT_AFTER == 0:\n",
    "            rand_idx = list(np.arange(0, X.shape[0]))\n",
    "            random.shuffle(rand_idx)\n",
    "            test_idx = rand_idx[:TEST_BATCH_SIZE]\n",
    "            before = torch.from_numpy(X[test_idx]).float().to(gpu)\n",
    "            ctrl = torch.empty(len(test_idx), dim_u).to(gpu)\n",
    "            after = torch.from_numpy(X_next[test_idx]).float().to(gpu)\n",
    "            next_pre_rec = model.predict(before, ctrl)\n",
    "            x_next_reconst_loss = (after - next_pre_rec).pow(2).sum(dim=1).mean().detach().cpu().numpy()\n",
    "#             x_reconst = model.decoder.eval()(model.encoder.eval()(before)[0])\n",
    "#             x_reconst_loss = (before - x_reconst).pow(2).sum(dim=1).mean().detach().cpu().numpy()\n",
    "            print('Average reconstruction loss: {}'.format(x_next_reconst_loss))\n",
    "\n",
    "            fig = plt.figure(figsize=(8,8))\n",
    "            fig.add_subplot(1,3,1)\n",
    "            rando_idx = np.random.randint(0,TEST_BATCH_SIZE)\n",
    "            plt.imshow(before[rando_idx,:,:,:].cpu().detach().numpy().transpose(1,2,0))\n",
    "            fig.add_subplot(1,3,2)\n",
    "            plt.imshow(after[rando_idx,:,:,:].cpu().detach().numpy().transpose(1,2,0))\n",
    "            fig.add_subplot(1,3,3)\n",
    "#             img_reconstruct = x_reconst[rando_idx,:,:,:].cpu().detach().numpy()\n",
    "            img_reconstruct = next_pre_rec[rando_idx,:,:,:].cpu().detach().numpy()\n",
    "            img_reconstruct = np.minimum(img_reconstruct, 1.)  # saturate pixel values to [0,1]\n",
    "            img_reconstruct = np.maximum(img_reconstruct, 0.)\n",
    "            plt.imshow(img_reconstruct.transpose(1,2,0))\n",
    "\n",
    "            dir_name = 'reconst_img'\n",
    "            if not os.path.exists(dir_name):\n",
    "                os.makedirs(dir_name)\n",
    "            plt.savefig('{}/{}.png'.format(dir_name,itr))\n",
    "            plt.close()\n",
    "\n",
    "        if itr % SAVEPOINT_AFTER == 0:\n",
    "            fn_pt_model = \"./dump.pt\"\n",
    "#             torch.save(model.state_dict(), fn_pt_model)\n",
    "#             print(\"Saved model at {}\".format(fn_pt_model))\n",
    "\n",
    "        itr += 1\n",
    "\n",
    "#         print('loss_rec:{}, loss_trans:{}'.format(loss_rec.item(), loss_trans.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9573303400>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate some random dummy image\n",
    "img_inp, img_next = None, None\n",
    "while img_inp is None or img_next is None:\n",
    "    x0 = np.hstack((posbounds[1] * np.random.rand(2), velmax*np.ones(2)))\n",
    "    img_inp = create_img(x0, posbounds)\n",
    "    x0_new = step(x0, Ak)\n",
    "    img_next = create_img(x0_new, posbounds)\n",
    "    \n",
    "X_rand = np.zeros((2,3,W,W))\n",
    "X_rand[0,:,:,:] = img_inp\n",
    "\n",
    "before = torch.from_numpy(X_rand).float().to(gpu)\n",
    "# img_reconstruct = model.decoder.eval()(model.encoder.eval()(before)[0])[overfit_idx,:,:,:].detach().cpu().numpy()\n",
    "ctrl = torch.empty(len(test_idx), dim_u).to(gpu)\n",
    "next_pre_rec = model.predict(before, ctrl)\n",
    "\n",
    "img_reconstruct = next_pre_rec[0].cpu().detach().numpy()\n",
    "img_reconstruct = np.minimum(img_reconstruct, 1.)  # saturate pixel values to [0,1]\n",
    "img_reconstruct = np.maximum(img_reconstruct, 0.)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    " \n",
    "# Input image\n",
    "fig.add_subplot(1,3,1)\n",
    "plt.imshow(img_inp.transpose(1,2,0))\n",
    "\n",
    "# \"True\" image that was overfit to\n",
    "fig.add_subplot(1,3,2)\n",
    "plt.imshow(img_next.transpose(1,2,0))\n",
    "\n",
    "fig.add_subplot(1,3,3)\n",
    "plt.imshow(img_reconstruct.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython import display\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# import gym\n",
    "# from gym import wrappers\n",
    "\n",
    "# env = gym.make('CartPole-v0')\n",
    "# # env = wrappers.Monitor(env, \"./gym-results\", force=True)\n",
    "# env.reset()\n",
    "\n",
    "# # plt.figure(figsize=(9,9))\n",
    "# # img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "\n",
    "# for _ in range(10):\n",
    "# #     img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "# #     display.display(plt.gcf())\n",
    "# #     display.clear_output(wait=True)\n",
    "\n",
    "#     obs, reward, done, info = env.step(env.action_space.sample())\n",
    "# #     env.render()\n",
    "#     if done:\n",
    "#         env.reset()\n",
    "\n",
    "# env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n-project",
   "language": "python",
   "name": "cs231n-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
