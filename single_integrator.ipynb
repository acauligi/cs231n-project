{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "from src.configs import BallEncoder, BallDecoder, BallTransition\n",
    "from src.e2c import E2C, compute_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to create (3,32,32) tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img(X, pos_bounds, radius=0.5, W=32):\n",
    "    x, y, vx, vy = X\n",
    "\n",
    "    # Check if center of ball outside image frame\n",
    "    if x < pos_bounds[0] or x > pos_bounds[1]:\n",
    "        return None\n",
    "    elif y < pos_bounds[0] or y > pos_bounds[1]:\n",
    "        return None\n",
    "\n",
    "    x_px = int(round(W * x / posbounds[1]))\n",
    "    y_px = int(round(W * y / posbounds[1]))\n",
    "    r_px = int(round(radius / pos_bounds[1] * W))\n",
    "\n",
    "    # Check if perimeter of ball outside image frame\n",
    "    if x_px+r_px > W or x_px-r_px < 0:\n",
    "        return None\n",
    "    elif y_px+r_px > W or y_px-r_px < 0:\n",
    "        return None\n",
    "\n",
    "    img = np.ones((3,W,W))\n",
    "    yy,xx = np.mgrid[:W, :W]\n",
    "    circle = (xx-x_px)**2 + (yy-y_px)**2\n",
    "    img[:, circle < r_px**2] = 0.\n",
    "\n",
    "    th = np.arctan2(vy,vx)\n",
    "    for rr in range(r_px):\n",
    "        img[0,int(y_px+rr*np.sin(th)), int(x_px+rr*np.cos(th))] = 1.\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PWA single integrator kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x0, Ak, add_noise=False):\n",
    "    # If ball in left-half plane, flip sign of vx\n",
    "    if x0[0] < 0.5*posbounds[1]:\n",
    "        x0[2] *= -1.\n",
    "\n",
    "    update = Ak @ x0\n",
    "    if add_noise:\n",
    "        mn = np.array([0.1, 0.1])\n",
    "        cov = np.diag([0.05, 0.05])\n",
    "        frzn = stats.multivariate_normal(mn, cov)\n",
    "        update += frzn.rvs(1)\n",
    "    return update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4 \n",
    "dh = 0.1\n",
    "\n",
    "posbounds = np.array([0,4]) # 4x4m square\n",
    "velmax = 10.\n",
    "\n",
    "Ak = np.eye(n)\n",
    "Ak[0:int(n/2), int(n/2):] = dh * np.eye(int(n/2))\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "W = 32\n",
    "NUM_DATA = 2\n",
    "\n",
    "X = np.zeros((NUM_DATA,3,W,W))\n",
    "X_next = np.zeros((NUM_DATA,3,W,W))\n",
    "\n",
    "count = 0\n",
    "while count < NUM_DATA:\n",
    "    x0 = np.hstack((posbounds[1] * np.random.rand(2), velmax*np.ones(2)))\n",
    "\n",
    "    img = create_img(x0, posbounds)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    x0_new = step(x0, Ak)\n",
    "    img_new = create_img(x0_new, posbounds)\n",
    "    if img_new is None:\n",
    "        continue\n",
    "\n",
    "    X[count,:,:,:] = img\n",
    "    X_next[count,:,:,:] = img_new\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb1323ee1d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 1\n",
    "img, img_next = X[idx], X_next[idx]\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow(img.transpose(1,2,0))\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(img_next.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct encoder/decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_in = X[0].shape\n",
    "dim_z = 6\n",
    "dim_u = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = E2C(dim_in, dim_z, dim_u, config='ball')\n",
    "inp = torch.from_numpy(X[:2]).float()\n",
    "\n",
    "mean, logvar = model.encode(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decode(mean).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.from_numpy(X[:2]).float()\n",
    "after = torch.from_numpy(X_next[:2]).float()\n",
    "ctrl = torch.empty(NUM_DATA, dim_u)\n",
    "\n",
    "model.forward(before, ctrl, after);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reconstruction loss: 0.3755623698234558\n",
      "Average reconstruction loss: 0.3601799011230469\n",
      "Average reconstruction loss: 0.36527857184410095\n",
      "Average reconstruction loss: 0.36364293098449707\n",
      "Average reconstruction loss: 0.3790653347969055\n",
      "Average reconstruction loss: 0.37956729531288147\n",
      "Average reconstruction loss: 0.3899807333946228\n",
      "Average reconstruction loss: 0.5519022345542908\n",
      "Average reconstruction loss: 0.39130645990371704\n",
      "Average reconstruction loss: 0.4882790744304657\n",
      "Average reconstruction loss: 0.4696277379989624\n",
      "Average reconstruction loss: 0.4134254455566406\n",
      "Average reconstruction loss: 0.5641186237335205\n",
      "Average reconstruction loss: 0.5207706689834595\n",
      "Average reconstruction loss: 0.4976283311843872\n",
      "Average reconstruction loss: 0.6018413305282593\n",
      "Average reconstruction loss: 0.5708572864532471\n",
      "Average reconstruction loss: 0.43165597319602966\n",
      "Average reconstruction loss: 0.4646272361278534\n",
      "Average reconstruction loss: 0.4633016288280487\n",
      "Average reconstruction loss: 0.4664532542228699\n",
      "Average reconstruction loss: 0.5270117521286011\n",
      "Average reconstruction loss: 0.4912235736846924\n",
      "Average reconstruction loss: 0.6208049654960632\n",
      "Average reconstruction loss: 0.45903339982032776\n",
      "Average reconstruction loss: 0.5896763801574707\n",
      "Average reconstruction loss: 0.6474175453186035\n",
      "Average reconstruction loss: 0.4529086649417877\n",
      "Average reconstruction loss: 0.5204428434371948\n",
      "Average reconstruction loss: 0.5445590615272522\n",
      "Average reconstruction loss: 0.45607680082321167\n",
      "Average reconstruction loss: 0.45114582777023315\n",
      "Average reconstruction loss: 0.4395485818386078\n",
      "Average reconstruction loss: 0.4189605116844177\n",
      "Average reconstruction loss: 0.44317251443862915\n",
      "Average reconstruction loss: 0.46856439113616943\n",
      "Average reconstruction loss: 0.49896955490112305\n",
      "Average reconstruction loss: 0.43100619316101074\n",
      "Average reconstruction loss: 0.45414862036705017\n",
      "Average reconstruction loss: 0.42276954650878906\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# training parameters\n",
    "TRAINING_ITERATIONS = int(100000)\n",
    "BATCH_SIZE = int(2)\n",
    "CHECKPOINT_AFTER = int(2500)\n",
    "SAVEPOINT_AFTER = int(20000)\n",
    "TEST_BATCH_SIZE = int(2)\n",
    "\n",
    "rand_idx = list(np.arange(0, X_next.shape[0]-1))\n",
    "indices = [rand_idx[ii * BATCH_SIZE:(ii + 1) * BATCH_SIZE] \\\n",
    "    for ii in range((len(rand_idx) + BATCH_SIZE - 1)     // BATCH_SIZE)]\n",
    "if len(indices[-1]) == 1:\n",
    "    # make sure batch doesn't just have one data point\n",
    "    indices[-1].append(indices[-1][0])\n",
    "\n",
    "itr = 1\n",
    "for epoch in range(TRAINING_ITERATIONS):\n",
    "    for ii, idx in enumerate(indices):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        before = torch.from_numpy(X[idx]).float()\n",
    "        ctrl = torch.empty(len(idx), dim_u)\n",
    "        after = torch.from_numpy(X_next[idx]).float()\n",
    "\n",
    "        next_pre_rec = model(before, ctrl, after)\n",
    "\n",
    "        loss_rec, loss_trans = compute_loss(\\\n",
    "            model.x_dec, model.x_next_pred_dec, \\\n",
    "            before, after, \\\n",
    "            model.Qz, model.Qz_next_pred, model.Qz_next, mse=True)\n",
    "\n",
    "        loss = loss_rec # + loss_trans\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if itr % CHECKPOINT_AFTER == 0:\n",
    "            rand_idx = list(np.arange(0, X.shape[0]))\n",
    "            random.shuffle(rand_idx)\n",
    "            test_idx = rand_idx[:TEST_BATCH_SIZE]\n",
    "            before = torch.from_numpy(X[test_idx]).float()\n",
    "            ctrl = torch.empty(len(test_idx), dim_u)\n",
    "            after = torch.from_numpy(X_next[test_idx]).float()\n",
    "            next_pre_rec = model(before, ctrl, after)\n",
    "            x_next_reconst_loss = (before - next_pre_rec).pow(2).sum(dim=1).mean().detach().numpy()\n",
    "            print('Average reconstruction loss: {}'.format(x_next_reconst_loss))\n",
    "\n",
    "        if itr % SAVEPOINT_AFTER == 0:\n",
    "            fn_pt_model = \"./dump.pt\"\n",
    "#             torch.save(model.state_dict(), fn_pt_model)\n",
    "#             print(\"Saved model at {}\".format(fn_pt_model))\n",
    "\n",
    "        itr += 1\n",
    "\n",
    "#         print('loss_rec:{}, loss_trans:{}'.format(loss_rec.item(), loss_trans.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb11e8cfcf8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 2\n",
    "overfit_idx = 0\n",
    "img_overfit = X[overfit_idx]\n",
    "\n",
    "# Generate some random dummy image\n",
    "img_inp = None\n",
    "while img_inp is None:\n",
    "    x0 = np.hstack((posbounds[1] * np.random.rand(2), velmax*np.ones(2)))\n",
    "    img_inp = create_img(x0, posbounds)\n",
    "X_rand = np.zeros((1,3,W,W))\n",
    "X_rand[0,:,:,:] = img_inp\n",
    "\n",
    "before = torch.from_numpy(X_rand).float()\n",
    "ctrl = torch.empty(before.shape[0], dim_u)\n",
    "img_reconstruct = model.decode(model.encode(before)[0])[overfit_idx,:,:,:].detach().numpy()\n",
    "img_reconstruct = np.minimum(img_reconstruct, 1.)  # saturate pixel values to [0,1]\n",
    "img_reconstruct = np.maximum(img_reconstruct, 0.)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    " \n",
    "# Input image\n",
    "fig.add_subplot(1,3,1)\n",
    "plt.imshow(X_rand[0,:,:,:].transpose(1,2,0))\n",
    "\n",
    "# \"True\" image that was overfit to\n",
    "fig.add_subplot(1,3,2)\n",
    "plt.imshow(img_overfit.transpose(1,2,0))\n",
    "\n",
    "fig.add_subplot(1,3,3)\n",
    "plt.imshow(img_reconstruct.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython import display\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# import gym\n",
    "# from gym import wrappers\n",
    "\n",
    "# env = gym.make('CartPole-v0')\n",
    "# # env = wrappers.Monitor(env, \"./gym-results\", force=True)\n",
    "# env.reset()\n",
    "\n",
    "# # plt.figure(figsize=(9,9))\n",
    "# # img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "\n",
    "# for _ in range(10):\n",
    "# #     img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "# #     display.display(plt.gcf())\n",
    "# #     display.clear_output(wait=True)\n",
    "\n",
    "#     obs, reward, done, info = env.step(env.action_space.sample())\n",
    "# #     env.render()\n",
    "#     if done:\n",
    "#         env.reset()\n",
    "\n",
    "# env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n-project",
   "language": "python",
   "name": "cs231n-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
