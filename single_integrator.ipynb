{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "from src.configs import BallEncoder, BallDecoder, BallTransition\n",
    "from src.e2c import E2C, compute_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to create (3,32,32) tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img(X, pos_bounds, radius=0.5, W=32):\n",
    "    x, y, vx, vy = X\n",
    "\n",
    "    # Check if center of ball outside image frame\n",
    "    if x < pos_bounds[0] or x > pos_bounds[1]:\n",
    "        return None\n",
    "    elif y < pos_bounds[0] or y > pos_bounds[1]:\n",
    "        return None\n",
    "\n",
    "    x_px = int(round(W * x / posbounds[1]))\n",
    "    y_px = int(round(W * y / posbounds[1]))\n",
    "    r_px = int(round(radius / pos_bounds[1] * W))\n",
    "\n",
    "    # Check if perimeter of ball outside image frame\n",
    "    if x_px+r_px > W or x_px-r_px < 0:\n",
    "        return None\n",
    "    elif y_px+r_px > W or y_px-r_px < 0:\n",
    "        return None\n",
    "\n",
    "    img = np.ones((3,W,W))\n",
    "    yy,xx = np.mgrid[:W, :W]\n",
    "    circle = (xx-x_px)**2 + (yy-y_px)**2\n",
    "    img[:, circle < r_px**2] = 0.\n",
    "\n",
    "    th = np.arctan2(vy,vx)\n",
    "    for rr in range(r_px):\n",
    "        img[0,int(y_px+rr*np.sin(th)), int(x_px+rr*np.cos(th))] = 1.\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PWA single integrator kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x0, Ak, add_noise=False):\n",
    "    # If ball in left-half plane, flip sign of vx\n",
    "    if x0[0] < 0.5*posbounds[1]:\n",
    "        x0[2] *= -1.\n",
    "\n",
    "    update = Ak @ x0\n",
    "    if add_noise:\n",
    "        mn = np.array([0.1, 0.1])\n",
    "        cov = np.diag([0.05, 0.05])\n",
    "        frzn = stats.multivariate_normal(mn, cov)\n",
    "        update += frzn.rvs(1)\n",
    "    return update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4 \n",
    "dh = 0.1\n",
    "\n",
    "posbounds = np.array([0,4]) # 4x4m square\n",
    "velmax = 10.\n",
    "\n",
    "Ak = np.eye(n)\n",
    "Ak[0:int(n/2), int(n/2):] = dh * np.eye(int(n/2))\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "W = 32\n",
    "NUM_DATA = 500\n",
    "\n",
    "X = np.zeros((NUM_DATA,3,W,W))\n",
    "X_next = np.zeros((NUM_DATA,3,W,W))\n",
    "\n",
    "count = 0\n",
    "while count < NUM_DATA:\n",
    "    x0 = np.hstack((posbounds[1] * np.random.rand(2), velmax*np.ones(2)))\n",
    "\n",
    "    img = create_img(x0, posbounds)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    x0_new = step(x0, Ak)\n",
    "    img_new = create_img(x0_new, posbounds)\n",
    "    if img_new is None:\n",
    "        continue\n",
    "\n",
    "    X[count,:,:,:] = img\n",
    "    X_next[count,:,:,:] = img_new\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "img, img_next = X[idx], X_next[idx]\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow(img.transpose(1,2,0))\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(img_next.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct encoder/decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_in = X[0].shape\n",
    "dim_z = 6\n",
    "dim_u = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "model = E2C(dim_in, dim_z, dim_u, config='ball')\n",
    "model.to(gpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = torch.from_numpy(X[:2]).float().to(gpu)\n",
    "# mean, logvar = model.encode(inp)\n",
    "# model.decode(mean).shape\n",
    "\n",
    "# before = torch.from_numpy(X[:2]).float().to(gpu)\n",
    "# after = torch.from_numpy(X_next[:2]).float().to(gpu)\n",
    "# ctrl = torch.empty(NUM_DATA, dim_u).to(gpu)\n",
    "\n",
    "# model.forward(before, ctrl, after);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# training parameters\n",
    "TRAINING_ITERATIONS = int(1000000)\n",
    "BATCH_SIZE = int(32)\n",
    "CHECKPOINT_AFTER = int(1500)\n",
    "SAVEPOINT_AFTER = int(20000)\n",
    "TEST_BATCH_SIZE = int(128)\n",
    "\n",
    "rand_idx = list(np.arange(0, X_next.shape[0]-1))\n",
    "indices = [rand_idx[ii * BATCH_SIZE:(ii + 1) * BATCH_SIZE] \\\n",
    "    for ii in range((len(rand_idx) + BATCH_SIZE - 1)     // BATCH_SIZE)]\n",
    "if len(indices[-1]) == 1:\n",
    "    # make sure batch doesn't just have one data point\n",
    "    indices[-1].append(indices[-1][0])\n",
    "\n",
    "itr = 1\n",
    "for epoch in range(TRAINING_ITERATIONS):\n",
    "    for ii, idx in enumerate(indices):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        before = torch.from_numpy(X[idx]).float().to(gpu)\n",
    "        ctrl = torch.empty(len(idx), dim_u).to(gpu)\n",
    "        after = torch.from_numpy(X_next[idx]).float().to(gpu)\n",
    "#         after = np.copy(X[idx])\n",
    "#         for jj in range(len(idx)):\n",
    "#             after[jj,:,:,:] = X[0]\n",
    "#         after = torch.from_numpy(after).float().to(gpu)\n",
    "\n",
    "        next_pre_rec = model(before, ctrl, after)\n",
    "\n",
    "        loss_rec, loss_trans = compute_loss(\\\n",
    "            model.x_dec, model.x_next_pred_dec, \\\n",
    "            before, after, \\\n",
    "            model.Qz, model.Qz_next_pred, model.Qz_next)\n",
    "\n",
    "        loss = loss_rec # + loss_trans\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if itr % CHECKPOINT_AFTER == 0:\n",
    "            rand_idx = list(np.arange(0, X.shape[0]))\n",
    "            random.shuffle(rand_idx)\n",
    "            test_idx = rand_idx[:TEST_BATCH_SIZE]\n",
    "            before = torch.from_numpy(X[test_idx]).float().to(gpu)\n",
    "            ctrl = torch.empty(len(test_idx), dim_u).to(gpu)\n",
    "            after = torch.from_numpy(X_next[test_idx]).float().to(gpu)\n",
    "            next_pre_rec = model.eval()(before, ctrl, after)\n",
    "            x_next_reconst_loss = (before - next_pre_rec).pow(2).sum(dim=1).mean().detach().cpu().numpy()\n",
    "#             x_reconst = model.decode(model.encode(before, use_eval=True)[0], use_eval=True)\n",
    "#             x_reconst_loss = (before - x_reconst).pow(2).sum(dim=1).mean().detach().cpu().numpy()\n",
    "            print('Average reconstruction loss: {}'.format(x_next_reconst_loss))\n",
    "\n",
    "            fig = plt.figure(figsize=(8,8))\n",
    "            fig.add_subplot(1,2,1)\n",
    "            rando_idx = np.random.randint(0,TEST_BATCH_SIZE)\n",
    "            plt.imshow(before[rando_idx,:,:,:].cpu().detach().numpy().transpose(1,2,0))\n",
    "            fig.add_subplot(1,2,2)\n",
    "#             img_reconstruct = x_reconst[rando_idx,:,:,:].cpu().detach().numpy()\n",
    "            img_reconstruct = next_pre_rec[rando_idx,:,:,:].cpu().detach().numpy()\n",
    "            img_reconstruct = np.minimum(img_reconstruct, 1.)  # saturate pixel values to [0,1]\n",
    "            img_reconstruct = np.maximum(img_reconstruct, 0.)\n",
    "            plt.imshow(img_reconstruct.transpose(1,2,0))\n",
    "\n",
    "            dir_name = 'reconst_img'\n",
    "            if not os.path.exists(dir_name):\n",
    "                os.makedirs(dir_name)\n",
    "            plt.savefig('{}/{}.png'.format(dir_name,itr))\n",
    "            plt.close()\n",
    "\n",
    "        if itr % SAVEPOINT_AFTER == 0:\n",
    "            fn_pt_model = \"./dump.pt\"\n",
    "#             torch.save(model.state_dict(), fn_pt_model)\n",
    "#             print(\"Saved model at {}\".format(fn_pt_model))\n",
    "\n",
    "        itr += 1\n",
    "\n",
    "#         print('loss_rec:{}, loss_trans:{}'.format(loss_rec.item(), loss_trans.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "overfit_idx = 0\n",
    "img_overfit = X[overfit_idx]\n",
    "\n",
    "# Generate some random dummy image\n",
    "img_inp = None\n",
    "while img_inp is None:\n",
    "    x0 = np.hstack((posbounds[1] * np.random.rand(2), velmax*np.ones(2)))\n",
    "    img_inp = create_img(x0, posbounds)\n",
    "X_rand = np.zeros((2,3,W,W))\n",
    "X_rand[0,:,:,:] = img_inp\n",
    "\n",
    "before = torch.from_numpy(X_rand).float().to(gpu)\n",
    "img_reconstruct = model.decode(model.encode(before, use_eval=True)[0], use_eval=True)[overfit_idx,:,:,:].detach().cpu().numpy()\n",
    "# ctrl = torch.empty(len(test_idx), dim_u).to(gpu)\n",
    "# next_pre_rec = model.predict(before, ctrl)\n",
    "# img_reconstruct = next_pre_rec[0].cpu().detach().numpy()\n",
    "\n",
    "img_reconstruct = np.minimum(img_reconstruct, 1.)  # saturate pixel values to [0,1]\n",
    "img_reconstruct = np.maximum(img_reconstruct, 0.)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    " \n",
    "# Input image\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow(X_rand[0,:,:,:].transpose(1,2,0))\n",
    "\n",
    "# # \"True\" image that was overfit to\n",
    "# fig.add_subplot(1,3,2)\n",
    "# plt.imshow(img_overfit.transpose(1,2,0))\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(img_reconstruct.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython import display\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# import gym\n",
    "# from gym import wrappers\n",
    "\n",
    "# env = gym.make('CartPole-v0')\n",
    "# # env = wrappers.Monitor(env, \"./gym-results\", force=True)\n",
    "# env.reset()\n",
    "\n",
    "# # plt.figure(figsize=(9,9))\n",
    "# # img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "\n",
    "# for _ in range(10):\n",
    "# #     img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "# #     display.display(plt.gcf())\n",
    "# #     display.clear_output(wait=True)\n",
    "\n",
    "#     obs, reward, done, info = env.step(env.action_space.sample())\n",
    "# #     env.render()\n",
    "#     if done:\n",
    "#         env.reset()\n",
    "\n",
    "# env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n-project",
   "language": "python",
   "name": "cs231n-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
